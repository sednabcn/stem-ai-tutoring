name: Fetch News Daily

on:
  schedule:
    - cron: '0 6 * * *'   # Runs daily at 6 AM UTC (fixed syntax)
  workflow_dispatch:       # Allows manual triggering
    inputs:
      news_category:
        description: 'News category to fetch'
        required: false
        default: 'science'
        type: choice
        options:
          - science
          - technology
          - education
          - general
      page_size:
        description: 'Number of articles to fetch'
        required: false
        default: '5'
        type: string

jobs:
  fetch-news:
    runs-on: ubuntu-latest
    
    steps:
    - name: ðŸ“¥ Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: ðŸ”§ Set up Git configuration
      run: |
        git config --global user.name "GitHub Actions Bot"
        git config --global user.email "actions@github.com"
        git config --global pull.rebase true

    - name: ðŸ”„ Pull latest changes
      run: |
        git fetch origin
        git pull origin main --rebase || git pull origin master --rebase

    - name: ðŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: ðŸ“ Ensure data directory exists
      run: |
        mkdir -p data
        mkdir -p .github/scripts

    - name: ðŸ“¡ Fetch raw news from NewsAPI
      env:
        NEWS_API_KEY: ${{ secrets.THENEWSAPI_KEY }}
        NEWS_CATEGORY: ${{ github.event.inputs.news_category || 'science' }}
        PAGE_SIZE: ${{ github.event.inputs.page_size || '5' }}
      run: |
        echo "ðŸ” Fetching news: category=$NEWS_CATEGORY, pageSize=$PAGE_SIZE"
        
        # Create raw news file with error handling
        curl -s "https://newsapi.org/v2/top-headlines?country=us&category=$NEWS_CATEGORY&pageSize=$PAGE_SIZE&apiKey=$NEWS_API_KEY" \
          -H "User-Agent: GitHub-Actions-News-Fetcher/1.0" \
          -w "HTTP Status: %{http_code}\n" \
          -o data/news_raw.json
        
        # Check if curl was successful
        if [ $? -eq 0 ]; then
          echo "âœ… Successfully fetched raw news data"
          
          # Validate JSON structure
          if python3 -c "import json; json.load(open('data/news_raw.json'))"; then
            echo "âœ… Raw news JSON is valid"
          else
            echo "âŒ Raw news JSON is invalid, creating empty structure"
            echo '{"status":"error","articles":[]}' > data/news_raw.json
          fi
        else
          echo "âŒ Failed to fetch news, creating fallback structure"
          echo '{"status":"error","articles":[]}' > data/news_raw.json
        fi

    - name: ðŸ”§ Install Python dependencies
      run: |
        python3 -m pip install --upgrade pip
        # No additional dependencies needed for this script

    - name: ðŸ“° Process news with display-news.py
      run: |
        echo "ðŸš€ Running news processing script..."
        
        # Copy display-news.py to the correct location if it exists in the repo
        if [ -f ".github/scripts/display-news.py" ]; then
          echo "âœ… Using existing display-news.py from repository"
        else
          echo "ðŸ“ Creating display-news.py script..."
          cat > .github/scripts/display-news.py << 'EOF'
        #!/usr/bin/env python3
        """
        News Display Script for GitHub Actions
        Processes and validates news data from NewsAPI for display in scripts.js
        """
        
        import json
        import os
        import sys
        from datetime import datetime, timezone
        from typing import Dict, List, Any, Optional
        
        class NewsProcessor:
            """Handles news data processing and validation"""
            
            def __init__(self, input_file: str = "data/news_raw.json", output_file: str = "data/news.json"):
                self.input_file = input_file
                self.output_file = output_file
                self.processed_data = {}
            
            def load_raw_news(self) -> Optional[Dict[str, Any]]:
                """Load raw news data from NewsAPI response"""
                try:
                    if not os.path.exists(self.input_file):
                        print(f"âŒ Input file not found: {self.input_file}")
                        return None
                    
                    with open(self.input_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    print(f"âœ… Loaded raw news data from {self.input_file}")
                    return data
                
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON decode error: {e}")
                    return None
                except Exception as e:
                    print(f"âŒ Error loading news: {e}")
                    return None
            
            def validate_article(self, article: Dict[str, Any]) -> bool:
                """Validate individual news article"""
                required_fields = ['title', 'source']
                
                # Check required fields exist
                for field in required_fields:
                    if field not in article or not article[field]:
                        return False
                
                # Validate source structure
                if not isinstance(article['source'], dict) or 'name' not in article['source']:
                    return False
                
                # Filter out articles with generic or placeholder titles
                title = article['title'].lower()
                invalid_phrases = [
                    '[removed]',
                    'untitled',
                    'no title'
                ]
                
                if any(phrase in title for phrase in invalid_phrases):
                    return False
                
                # Ensure title is not too short or too long
                if len(article['title'].strip()) < 10 or len(article['title']) > 200:
                    return False
                
                return True
            
            def process_articles(self, raw_data: Dict[str, Any]) -> List[Dict[str, Any]]:
                """Process and filter articles from NewsAPI response"""
                if 'articles' not in raw_data or not isinstance(raw_data['articles'], list):
                    print("âŒ No valid articles array found in data")
                    return []
                
                valid_articles = []
                
                for i, article in enumerate(raw_data['articles']):
                    if self.validate_article(article):
                        processed_article = {
                            'title': article['title'].strip(),
                            'source': {
                                'name': article['source']['name']
                            },
                            'description': article.get('description', '').strip()[:100] + '...' if article.get('description') else '',
                            'url': article.get('url', ''),
                            'publishedAt': article.get('publishedAt', ''),
                            'processed_at': datetime.now(timezone.utc).isoformat()
                        }
                        valid_articles.append(processed_article)
                        print(f"âœ… Article {i+1}: {article['title'][:50]}...")
                    else:
                        print(f"âŒ Article {i+1}: Invalid or filtered out")
                
                return valid_articles
            
            def create_fallback_news(self) -> List[Dict[str, Any]]:
                """Create fallback news when API fails"""
                fallback_articles = [
                    {
                        'title': 'Breaking: Scientists discover new method for faster learning',
                        'source': {'name': 'Science Daily'},
                        'description': 'Revolutionary approach to accelerated learning techniques...',
                        'url': '#',
                        'publishedAt': datetime.now(timezone.utc).isoformat(),
                        'processed_at': datetime.now(timezone.utc).isoformat()
                    },
                    {
                        'title': 'Education News: Online tutoring platform shows 85% improvement rates',
                        'source': {'name': 'EdTech Weekly'},
                        'description': 'Comprehensive study reveals significant learning gains...',
                        'url': '#',
                        'publishedAt': datetime.now(timezone.utc).isoformat(),
                        'processed_at': datetime.now(timezone.utc).isoformat()
                    },
                    {
                        'title': 'Tech Update: AI-powered study tools gain popularity among students',
                        'source': {'name': 'TechCrunch'},
                        'description': 'Artificial intelligence transforms educational landscape...',
                        'url': '#',
                        'publishedAt': datetime.now(timezone.utc).isoformat(),
                        'processed_at': datetime.now(timezone.utc).isoformat()
                    },
                    {
                        'title': 'Research: Personalized learning approaches show promising results',
                        'source': {'name': 'Educational Research'},
                        'description': 'Tailored educational methods demonstrate effectiveness...',
                        'url': '#',
                        'publishedAt': datetime.now(timezone.utc).isoformat(),
                        'processed_at': datetime.now(timezone.utc).isoformat()
                    },
                    {
                        'title': 'Innovation: New digital classroom technologies enhance engagement',
                        'source': {'name': 'Digital Learning'},
                        'description': 'Interactive technologies boost student participation...',
                        'url': '#',
                        'publishedAt': datetime.now(timezone.utc).isoformat(),
                        'processed_at': datetime.now(timezone.utc).isoformat()
                    }
                ]
                
                print(f"ðŸ”„ Created {len(fallback_articles)} fallback news articles")
                return fallback_articles
            
            def process_news(self) -> bool:
                """Main processing function"""
                print("ðŸ“° Starting news processing...")
                
                # Load raw data
                raw_data = self.load_raw_news()
                
                if raw_data is None or raw_data.get('status') == 'error':
                    print("âš ï¸ Using fallback news due to API error or load failure")
                    articles = self.create_fallback_news()
                else:
                    # Process articles
                    articles = self.process_articles(raw_data)
                    
                    # Use fallback if no valid articles found
                    if not articles:
                        print("âš ï¸ No valid articles found, using fallback news")
                        articles = self.create_fallback_news()
                
                # Create final data structure compatible with scripts.js
                self.processed_data = {
                    'status': 'success',
                    'totalResults': len(articles),
                    'articles': articles,
                    'lastUpdated': datetime.now(timezone.utc).isoformat(),
                    'source': 'NewsAPI' if raw_data and raw_data.get('status') != 'error' else 'Fallback',
                    'metadata': {
                        'processed_by': 'GitHub Actions',
                        'script_version': '1.0.0',
                        'compatible_with': 'scripts.js NewsManager'
                    }
                }
                
                print(f"âœ… Processed {len(articles)} articles successfully")
                return True
            
            def save_processed_news(self) -> bool:
                """Save processed news to output file"""
                try:
                    # Ensure output directory exists
                    output_dir = os.path.dirname(self.output_file)
                    if output_dir and not os.path.exists(output_dir):
                        os.makedirs(output_dir)
                        print(f"ðŸ“ Created directory: {output_dir}")
                    
                    # Write processed data
                    with open(self.output_file, 'w', encoding='utf-8') as f:
                        json.dump(self.processed_data, f, indent=2, ensure_ascii=False)
                    
                    print(f"ðŸ’¾ Saved processed news to {self.output_file}")
                    
                    # Display sample for verification
                    if self.processed_data.get('articles'):
                        print("\nðŸ“‹ Sample processed articles:")
                        for i, article in enumerate(self.processed_data['articles'][:3], 1):
                            print(f"  {i}. {article['title']} â€” {article['source']['name']}")
                    
                    return True
                
                except Exception as e:
                    print(f"âŒ Error saving processed news: {e}")
                    return False
            
            def display_stats(self):
                """Display processing statistics"""
                if not self.processed_data:
                    print("âŒ No processed data available")
                    return
                
                print("\nðŸ“Š Processing Statistics:")
                print(f"  â€¢ Total articles: {self.processed_data.get('totalResults', 0)}")
                print(f"  â€¢ Data source: {self.processed_data.get('source', 'Unknown')}")
                print(f"  â€¢ Last updated: {self.processed_data.get('lastUpdated', 'Unknown')}")
                print(f"  â€¢ Status: {self.processed_data.get('status', 'Unknown')}")
        
        def main():
            """Main execution function"""
            print("ðŸš€ News Display Script Starting...")
            
            # Initialize processor
            processor = NewsProcessor()
            
            # Process news
            if not processor.process_news():
                print("âŒ News processing failed")
                sys.exit(1)
            
            # Save processed news
            if not processor.save_processed_news():
                print("âŒ Failed to save processed news")
                sys.exit(1)
            
            # Display statistics
            processor.display_stats()
            
            print("\nâœ… News processing completed successfully!")
            print("ðŸ”— News data is now ready for scripts.js NewsManager")
        
        if __name__ == "__main__":
            main()
        EOF
          
          chmod +x .github/scripts/display-news.py
        fi
        
        # Run the news processing script
        python3 .github/scripts/display-news.py

    - name: ðŸ§¹ Cleanup temporary files
      run: |
        # Remove raw news file to keep repo clean
        rm -f data/news_raw.json
        echo "ðŸ—‘ï¸ Cleaned up temporary files"

    - name: ðŸ” Validate processed news
      run: |
        echo "ðŸ” Validating final news.json..."
        
        if [ -f "data/news.json" ]; then
          # Check if JSON is valid
          if python3 -c "import json; data=json.load(open('data/news.json')); print(f'âœ… Valid JSON with {len(data.get(\"articles\", []))} articles')"; then
            echo "âœ… News validation successful"
            
            # Display first article title for verification
            python3 -c "
import json
with open('data/news.json', 'r') as f:
    data = json.load(f)
    if data.get('articles'):
        print(f'ðŸ“° First article: {data[\"articles\"][0][\"title\"][:60]}...')
        print(f'ðŸ“Š Total articles: {len(data[\"articles\"])}')
        print(f'ðŸ•’ Last updated: {data.get(\"lastUpdated\", \"Unknown\")}')
    else:
        print('âš ï¸ No articles found in processed data')
"
          else
            echo "âŒ Invalid JSON structure"
            exit 1
          fi
        else
          echo "âŒ news.json file not found"
          exit 1
        fi

    - name: ðŸ“ Check for changes
      id: check_changes
      run: |
        if git diff --quiet data/news.json; then
          echo "no_changes=true" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ No changes detected in news data"
        else
          echo "no_changes=false" >> $GITHUB_OUTPUT
          echo "ðŸ“‹ Changes detected in news data"
          git diff --stat data/news.json
        fi

    - name: ðŸ’¾ Commit and push updated news
      if: steps.check_changes.outputs.no_changes == 'false'
      run: |
        echo "ðŸ“¤ Committing updated news data..."
        
        git add data/news.json
        git add .github/scripts/display-news.py 2>/dev/null || true  # Add script if it was created
        
        # Create detailed commit message
        COMMIT_MSG="ðŸ“° Update news - $(date '+%Y-%m-%d %H:%M UTC')"
        
        # Add article count to commit message
        ARTICLE_COUNT=$(python3 -c "import json; print(len(json.load(open('data/news.json')).get('articles', [])))" 2>/dev/null || echo "unknown")
        COMMIT_MSG="${COMMIT_MSG}

ðŸ”¢ Articles: ${ARTICLE_COUNT}
ðŸ¤– Automated by GitHub Actions
ðŸ”— Compatible with scripts.js NewsManager"

        git commit -m "$COMMIT_MSG" || {
          echo "âŒ Failed to commit changes"
          exit 1
        }
        
        # Push with retry logic
        for i in {1..3}; do
          if git push origin HEAD; then
            echo "âœ… Successfully pushed changes (attempt $i)"
            break
          else
            echo "âš ï¸ Push failed (attempt $i), retrying..."
            sleep 2
            git pull --rebase origin HEAD || true
          fi
        done

    - name: ðŸ“Š Job Summary
      if: always()
      run: |
        echo "## ðŸ“° News Fetch Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "data/news.json" ]; then
          ARTICLE_COUNT=$(python3 -c "import json; data=json.load(open('data/news.json')); print(len(data.get('articles', [])))" 2>/dev/null || echo "0")
          LAST_UPDATED=$(python3 -c "import json; data=json.load(open('data/news.json')); print(data.get('lastUpdated', 'Unknown'))" 2>/dev/null || echo "Unknown")
          DATA_SOURCE=$(python3 -c "import json; data=json.load(open('data/news.json')); print(data.get('source', 'Unknown'))" 2>/dev/null || echo "Unknown")
          
          echo "âœ… **Success**: News data updated successfully" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“Š Articles processed: **${ARTICLE_COUNT}**" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ•’ Last updated: **${LAST_UPDATED}**" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ“¡ Data source: **${DATA_SOURCE}**" >> $GITHUB_STEP_SUMMARY
          echo "- ðŸ”— **Compatible with scripts.js NewsManager**" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.check_changes.outputs.no_changes }}" == "true" ]; then
            echo "- ðŸ“‹ No changes detected (news already up to date)" >> $GITHUB_STEP_SUMMARY
          else
            echo "- ðŸ’¾ Changes committed and pushed to repository" >> $GITHUB_STEP_SUMMARY
          fi
        else
          echo "âŒ **Failed**: No news.json file generated" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "---" >> $GITHUB_STEP_SUMMARY
        echo "*Automated by GitHub Actions â€¢ $(date '+%Y-%m-%d %H:%M:%S UTC')*" >> $GITHUB_STEP_SUMMARY